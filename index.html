<!DOCTYPE html>
<html>

<head>
  <meta charset="utf-8">
  <!-- Meta tags for social media banners, these should be filled in appropriatly as they are your "business card" -->
  <!-- Replace the content tag with appropriate information -->
  <meta name="description"
    content="Project page for Fast and Uncertainty-Aware SVBRDF Recovery from Multi-View Capture using Frequency Domain Analysis">
  <meta property="og:title"
    content="Fast and Uncertainty-Aware SVBRDF Recovery from Multi-View Capture using Frequency Domain Analysis" />
  <meta property="og:description"
    content="Relightable object acquisition is a key challenge in simplifying digital asset creation. We approach this problem by leveraging frequency domain analysis, enabling fast optimization and a measure of uncertainty based on entropy." />
  <meta property="og:url" content="https://brdf-uncertainty.github.io" />
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X630-->
  <meta property="og:image" content="static/image/your_banner_image.png" />
  <meta property="og:image:width" content="1200" />
  <meta property="og:image:height" content="630" />


  <meta name="twitter:title"
    content="Fast and Uncertainty-Aware SVBRDF Recovery from Multi-View Capture using Frequency Domain Analysis">
  <meta name="twitter:description"
    content="Relightable object acquisition is a key challenge in simplifying digital asset creation. We approach this problem by leveraging frequency domain analysis, enabling fast optimization and a measure of uncertainty based on entropy.">
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X600-->
  <meta name="twitter:image" content="static/images/your_twitter_banner_image.png">
  <meta name="twitter:card" content="summary_large_image">
  <!-- Keywords for your paper to be indexed by-->
  <meta name="keywords"
    content="BRDF, SVBRDF, relighting, inverse rendering, differentiable rendering, spherical harmonics, acquisition, material, appearance">
  <meta name="viewport" content="width=device-width, initial-scale=1">


  <title>Fast and Uncertainty-Aware SVBRDF Recovery from Multi-View Capture using Frequency Domain Analysis</title>

  <link rel="icon" type="image/x-icon" href="static/images/favicon.ico">
  <link rel="stylesheet" href="https://use.typekit.net/fiu3sit.css">

  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="static/css/index.css">

  <script defer data-domain="brdf-uncertainty.github.io" src="https://plausible.io/js/script.js"></script>
  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script src="static/js/bulma-carousel.min.js"></script>
  <script src="static/js/bulma-slider.min.js"></script>
  <script src="static/js/index.js"></script>
</head>

<body>


  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-left">
            <h1 class="title is-2 publication-title">Fast and Uncertainty-Aware SVBRDF Recovery from Multi-View Capture
              using Frequency Domain Analysis</h1>
            <div class="is-size-5 publication-authors">
              <!-- Paper authors -->
              <span class="author-block">
                Anonymous authors,</span>

              <div class="is-size-5 publication-authors">
                <span class="author-block">ArXiv 2024</span>
              </div>
            </div>
            <div class="column has-text-left">
              <div class="publication-links">
                <!-- Arxiv PDF link -->
                <span class="link-block">
                  <a href="https://arxiv.org/pdf/2406.17774.pdf" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                    </span>
                    <span>Paper</span>
                  </a>
                </span>

                <!-- Supplementary PDF link -->
                <span class="link-block">
                  <a href="/suppmat" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fas fa-plus"></i>
                    </span>
                    <span>Supplementary</span>
                  </a>
                </span>

                <!-- Github link -->
                <span class="link-block">
                  <a href="#" target="_blank" class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-github"></i>
                    </span>
                    <span>Code (to be released)</span>
                  </a>
                </span>

                <!-- ArXiv abstract Link -->
                <span class="link-block">
                  <a href="http://arxiv.org/abs/2406.17774" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="ai ai-arxiv"></i>
                    </span>
                    <span>arXiv</span>
                  </a>
                </span>
              </div>
            </div>
          </div>
        </div>
      </div>
    </div>
  </section>

  <!-- Teaser image-->
  <section class="hero teaser">
    <div class="container is-max-desktop">
      <div class="hero-body">
        <img src="static/images/teaser.jpg" alt="Overview image." />
        <h2 class="subtitle has-text-left">
          We present fast and uncertainty-aware multi-view material acquisition for objects captured in uncontrolled
          setups.
          We propose to build upon and extend the signal processing framework for inverse rendering by
          Ramamoorthi and
          Hanrahan (2001): we improve the model with shadowing and masking and propose a lightweight objective
          function
          for BRDF fitting using spherical harmonics power spectra (center). We then use this approximation to
          provide a measure of uncertainty relying on statistical entropy. We show that our material estimation
          is
          significantly faster than previous work and achieves similar or better results (right).
        </h2>
      </div>
    </div>
  </section>
  <!-- End teaser image -->

  <!-- Paper abstract -->
  <section class="section hero is-light">
    <div class="container is-max-desktop">
      <div class="columns is-centered has-text-left">
        <div class="column is-four-fifths">
          <h2 class="title is-3">Abstract</h2>
          <div class="content has-text-left">
            <p>
              Relightable object acquisition is a key challenge in simplifying digital asset creation.
              Complete reconstruction of an object typically requires capturing hundreds to thousands of photographs
              under controlled illumination, with specialized equipment.
              The recent progress in differentiable rendering improved the quality and accessibility of inverse
              rendering optimization.
              Nevertheless, under uncontrolled illumination and unstructured viewpoints, there is no guarantee that the
              observations contain enough information to reconstruct the appearance properties of the captured object.
            </p>
            <p>
              We thus propose to consider the acquisition process from a signal-processing perspective.
              Given an object's geometry and a lighting environment, we estimate the properties of the materials on the
              object's surface in seconds.
              We do so by leveraging frequency domain analysis, considering the recovery of material properties as a
              deconvolution, enabling fast error estimation.
              We then quantify the uncertainty of the estimation, based on the available data, highlighting the areas
              for which priors or additional samples would be required for improved acquisition quality.
              We compare our approach to previous work and quantitatively evaluate our results, showing similar quality
              as previous work in a fraction of the time, and providing key information about the certainty of the
              results.
            </p>
          </div>
        </div>
      </div>
    </div>
  </section>
  <!-- End paper abstract -->


  <!--Problem statement -->
  <section class="section hero is-small" id="method">
    <div class="hero-body">
      <div class="container is-max-desktop has-text-left">
        <div class="columns is-centered has-text-left">
          <div class="column is-four-fifths">
            <div class="content">
              <h2 class="title is-3">Problem statement</h2>
              <p>The reflections we observe from an object inform us about the properties of its material.
                Sometimes, it is difficult to know what material we are dealing with if we miss
                certain reflections or if a part of the object is in the shade. This can happen, for example, on a
                cloudy
                day where a glossy surface looks similar to a matte surface under certain viewing angles.</p>
              <p>Which plane is glossy and which is matte? On the left, it's difficult to find out because of the
                lighting. On the right, it's immediately clear.</p>
            </div>
          </div>
        </div>
        <img src="static/images/problem_statement.png"
          alt="Two images that show the same matte and glossy surface in two lighting setups. The first image is rendered with a cloudy environment and the surfaces look similar. The second image is rendered with a sunny environment and the surfaces look very different." />
      </div>
    </div>
  </section>
  <!--End problem statement -->

  <!--Method overview -->
  <section class="section hero is-light is-small" id="method">
    <div class="hero-body">
      <div class="container is-max-desktop has-text-left">
        <div class="columns is-centered has-text-left">
          <div class="column is-four-fifths">
            <div class="content">
              <h2 class="title is-3">Overview</h2>
              <p>The question whether we have the right lighting- and viewing conditions can be posed as a question of
                uncertainty. In this paper, we aim to quantify this uncertainty. Our work differs from recent
                contributions on
                uncertainty in inverse rendering by approaching the reflection equation from the signal processing
                framework
                on inverse rendering (Ramamoorthi and Hanrahan, 2001). Along the way, we find that an improved version
                of
                this
                framework
              <ul>
                <li> can <b>match state-of-the-art results in a fraction of the time</b> on the task of BRDF recovery,
                </li>
                <li> while <b>providing a practical way to measure uncertainty</b>.</li>
              </ul>
              </p>
            </div>
          </div>
        </div>
      </div>
    </div>
    </div>
  </section>
  <!--End method overview -->

  <!-- Results -->
  <section class="section">
    <!-- Relighting -->
    <section class="hero is-small">
      <div class="hero-body">
        <div class="container is-max-desktop">
          <h2 class="title is-3">Relighting results</h2>
          <div id="results-carousel" class="carousel results-carousel">
            <div class="item item-object1">
              <div class="columns">
                <div class="column">
                  <h2 class="subtitle">Ours, <b>5.27</b>s</h2>
                  <video poster="" id="teapot_ours" autoplay muted playsinline loop width="100%">
                    <source src="static/video/gnome_scene003/video/sh/vid.mp4" type="video/mp4">
                  </video>
                </div>
                <div class="column">
                  <h2 class="subtitle">Ours + Mitsuba, <b>19.87</b>s</h2>
                  <video poster="" id="teapot_oursplus" autoplay muted playsinline loop width="100%">
                    <source src="static/video/gnome_scene003/video/oursplusmitsuba/vid.mp4" type="video/mp4">
                  </video>
                </div>
                <div class="column">
                  <h2 class="subtitle">Mitsuba, <b>69.96</b>s</h2>
                  <video poster="" id="teapot_mitsuba" autoplay muted playsinline loop width="100%">
                    <source src="static/video/gnome_scene003/video/mitsuba/vid.mp4" type="video/mp4">
                  </video>
                </div>
                <div class="column">
                  <h2 class="subtitle">NVDiffRec, <b>142.14</b>s</h2>
                  <video poster="" id="teapot_nv" autoplay muted playsinline loop width="100%">
                    <source src="static/video/gnome_scene003/video/nvdiffrec/vid.mp4" type="video/mp4">
                  </video>
                </div>
              </div>
            </div>
            <div class="item item-object2">
              <div class="columns">
                <div class="column">
                  <h2 class="subtitle">Ours, <b>5.27</b>s</h2>
                  <video poster="" id="teapot_ours" autoplay muted playsinline loop width="100%">
                    <source src="static/video/cactus_scene005/video/sh/vid.mp4" type="video/mp4">
                  </video>
                </div>
                <div class="column">
                  <h2 class="subtitle">Ours + Mitsuba, <b>19.87</b>s</h2>
                  <video poster="" id="teapot_oursplus" autoplay muted playsinline loop width="100%">
                    <source src="static/video/cactus_scene005/video/oursplusmitsuba/vid.mp4" type="video/mp4">
                  </video>
                </div>
                <div class="column">
                  <h2 class="subtitle">Mitsuba, <b>69.96</b>s</h2>
                  <video poster="" id="teapot_mitsuba" autoplay muted playsinline loop width="100%">
                    <source src="static/video/cactus_scene005/video/mitsuba/vid.mp4" type="video/mp4">
                  </video>
                </div>
                <div class="column">
                  <h2 class="subtitle">NVDiffRec, <b>142.14</b>s</h2>
                  <video poster="" id="teapot_nv" autoplay muted playsinline loop width="100%">
                    <source src="static/video/cactus_scene005/video/nvdiffrec/vid.mp4" type="video/mp4">
                  </video>
                </div>
              </div>
            </div>
            <div class="item item-object3">
              <div class="columns">
                <div class="column">
                  <h2 class="subtitle">Ours, <b>5.27</b>s</h2>
                  <video poster="" id="teapot_ours" autoplay mute playsinline loop width="100%">
                    <source src="static/video/teapot_scene001/video/sh/vid.mp4" type="video/mp4">
                  </video>
                </div>
                <div class="column">
                  <h2 class="subtitle">Ours + Mitsuba, <b>19.87</b>s</h2>
                  <video poster="" id="teapot_oursplus" autoplay muted playsinline loop width="100%">
                    <source src="static/video/teapot_scene001/video/oursplusmitsuba/vid.mp4" type="video/mp4">
                  </video>
                </div>
                <div class="column">
                  <h2 class="subtitle">Mitsuba, <b>69.96</b>s</h2>
                  <video poster="" id="teapot_mitsuba" autoplay muted playsinline loop width="100%">
                    <source src="static/video/teapot_scene001/video/mitsuba/vid.mp4" type="video/mp4">
                  </video>
                </div>
                <div class="column">
                  <h2 class="subtitle">NVDiffRec, <b>142.14</b>s</h2>
                  <video poster="" id="teapot_nv" autoplay muted playsinline loop width="100%">
                    <source src="static/video/teapot_scene001/video/nvdiffrec/vid.mp4" type="video/mp4">
                  </video>
                </div>
              </div>
            </div>

          </div>
          <p>We optimize a PBR texture (base color, metallicity, roughness) on multi-view captures from <a
              href="https://stanfordorb.github.io" target="_blank">Stanford ORB</a> and relight the resulting object in
            Blender.
            More results in the supplemental material and the paper.
          </p>
        </div>
      </div>
    </section>
    <!-- End relighting -->

    <!-- Uncertainty -->
    <section class="hero is-small">
      <div class="hero-body">
        <div class="container is-max-desktop">
          <div class="content">
            <h2 class="title is-3">Uncertainty results</h2>
            <p>We show that our formulation for uncertainty using entropy matches with errors resulting from an
              optimization with Mitsuba.</p>
            <br />
            <img src="static/images/uncertainty.png"
              alt="Results showing a BRDF texture that was optimized with Mitsuba. On the right, the error is shown and a map of the uncertainty." />
            <br /><br />
            <p>
              On the right, we show the average estimation error followed by our entropy estimation. We observe that low
              entropy is indicative of lower error, suggesting that it captures the sufficiency of information in the
              input signal. On the dice example (top row), the `one'-face is lit less than other faces and we observe
              highlights with lower intensity, leading to higher entropy. While we still recover the white albedo
              correctly, the estimation of roughness and metallicity for the dot has a high error. Similarly, the inside
              and lower parts of the doughnut are less observed and not lit by strong light sources. Again, entropy is
              high in regions of high error (especially in metallicity). The triceratops collar is down-facing and not
              well-lit and our entropy captures the lack of observation that leads to high error in the metallicity
              part.
            </p>
          </div>
        </div>
      </div>
    </section>
    <!-- End uncertainty -->
  </section>

  <!--Signal processing recap -->
  <section class="section hero is-light is-small" id="method">
    <div class="hero-body">
      <div class="container is-max-desktop has-text-left">
        <div class="columns is-centered has-text-left">
          <div class="column is-four-fifths">
            <div class="content">
              <h2 class="title is-3">Method</h2>
              <div class="columns">
                <div class="column is-8">
                  <div class="content">
                    <h3 class="title is-4">Reflection as Convolution</h3>
                    <p>The signal processing framework for inverse rendering (Ramamoorthi and Hanrahan, 2001) shows that
                      the reflection equation can be
                      approximated as a rotational convolution of the BRDF kernel with the incoming light over the
                      incoming-
                      and outgoing light directions at a point on the surface. This perspective allows us to study
                      inverse
                      rendering in the <i>frequency domain</i>, here the spherical harmonics domain.</p>
                  </div>
                </div>
                <div class="column is-4">
                  <img src="static/images/convolution.png"
                    alt="An image that shows the reflection equation as a convolution of the BRDF kernel with the incoming light over the incoming- and outgoing light directions at a point on the surface." />
                </div>
              </div>
            </div>
          </div>
        </div>
      </div>
    </div>
  </section>
  <!--End signal processing recap -->

  <!--Contributions overview -->
  <section class="section hero is-small" id="method">
    <div class="hero-body">
      <div class="container is-max-desktop has-text-left">
        <div class="columns is-centered has-text-left">
          <div class="column is-four-fifths">
            <div class="content">
              <div class="columns">
                <div class="column is-8">
                  <div class="content">
                    <h3 class="title is-4">Robust Spherical Harmonics Transform</h3>
                    <p>Our first contribution is a method to estimate the spherical harmonics coefficients for the
                      incoming- and outgoing radiance field, for sparse and irregularly distributed viewing positions.
                      We achieve this by a least-squares fit with a weighted L2 regularization.</p>
                  </div>
                </div>
                <div class="column is-4">
                  <img src="static/images/lsq_spherical_harmonics.png"
                    alt="An image that represents a procedure to fit spherical harmonics coefficients to an irregularly distributed, sparse set of points." />
                </div>
              </div>

              <hr /><br />

              <div class="columns">
                <div class="column is-8">
                  <div class="content">
                    <h3 class="title is-4">BRDF Recovery with Shadowing and Masking</h3>
                    <p>Our second contribution is to use these coefficients in a BRDF optimization pipeline to estimate
                      parameters for an analytic microfacet BRDF (Disney principled BRDF). We improve the accuracy of
                      the convolution model by incorporating shadowing and masking.</p>
                  </div>
                </div>
                <div class="column is-4">
                  <img src="static/images/shadowing_masking.png"
                    alt="An image that represents shadowing and masking." />
                </div>
              </div>

              <hr /><br />

              <div class="content">
                <h3 class="title is-4">Power Spectrum Approximation</h3>
                <p>Our third contribution is to develop an extremely light-weight approximation of the convolution model
                  that operates completely in the power spectrum of the spherical harmonics. This allows us to explore
                  hundreds of BRDF parameter combinations in a couple of milliseconds. Moreover, the power spectrum is
                  invariant to rotations of local coordinate frame (here, rotated normals).</p>
                <img src="static/images/power_spectrum.png"
                  alt="An image showing three plots, representing power spectra. The first plot is the power spectrum of the incoming light, the second plot of the BRDF and the third of the outgoing light. On the second plot, the graph shows alternative plots for different parameter combinations." />
              </div>

              <hr /><br />

              <div class="content">
                <h3 class="title is-4">Uncertainty as Entropy</h3>
                <p>Our final contribution is to use statistical entropy on the likelihood of BRDF parameters to
                  quantify uncertainty. While other methods test the likelihood function around a found optimum, our
                  method takes a global perspective on all possible BRDF parameter combinations. This is tractable due
                  to our power spectrum approximation.</p>
                <p>We show three examples of power spectra for incoming and outgoing radiance,
                  their corresponding likelihood and entropy in the adjacent figure.
                </p>
              </div>
            </div>
          </div>
        </div>
      </div>
    </div>
    <div class="hero-body">
      <div class="container is-max-desktop has-text-left">
        <div class="columns">
          <div class="column is-7">
            <img src="static/images/entropy.png"
              alt="An image showing three plots representing a likelihood and the corresponding entropy." />
          </div>
          <div class="column is-5">
            <div class="content">
              <p>
                The top row shows incoming light for a dirac delta light source (constant in
                the spherical harmonic domain) and we see that entropy is low (H=0.25); we can be very certain
                about the BRDF recovery.
              </p>
              <p>
                In the middle row, the light only has amplitude in low frequencies and many roughness values are
                equally likely.
                The higher entropy (H=0.69) is associated with higher uncertainty, which is in line with the
                conclusions from Ramamoorthi and Hanrahan (2001).
              </p>
              <p>
                The bottom row shows a material with very low specular reflectance, resulting in high entropy
                (H=0.87) and thus high uncertainty.
              </p>
            </div>
          </div>
        </div>
      </div>
    </div>
  </section>
  <!--End contributions overview -->

  <!--Find out more -->
  <section class="section hero is-light is-small" id="method">
    <div class="hero-body">
      <div class="container is-max-desktop has-text-left">
        <div class="columns is-centered has-text-left">
          <div class="column is-four-fifths">
            <div class="content">
              <h2 class="title is-3">Find out more</h2>
              <div class="publication-links">
                <!-- Arxiv PDF link -->
                <span class="link-block">
                  <a href="https://arxiv.org/pdf/2406.17774.pdf" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                    </span>
                    <span>Paper</span>
                  </a>
                </span>

                <!-- Supplementary PDF link -->
                <span class="link-block">
                  <a href="/suppmat" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fas fa-plus"></i>
                    </span>
                    <span>Supplementary</span>
                  </a>
                </span>

                <!-- Github link -->
                <span class="link-block">
                  <a href="#" target="_blank" class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-github"></i>
                    </span>
                    <span>Code (to be released)</span>
                  </a>
                </span>

                <!-- ArXiv abstract Link -->
                <span class="link-block">
                  <a href="http://arxiv.org/abs/2406.17774" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="ai ai-arxiv"></i>
                    </span>
                    <span>arXiv</span>
                  </a>
                </span>
              </div>
            </div>
          </div>
        </div>
      </div>
    </div>
  </section>
  <!--End find out more -->


  <!--BibTex citation -->
  <section class="section" id="BibTeX">
    <div class="container is-max-desktop content">
      <h2 class="title">BibTeX</h2>
      <pre><code>Coming soon</code></pre>
    </div>
  </section>
  <!--End BibTex citation -->

  <footer class="footer">
    <div class="container">
      <div class="columns is-centered">
        <div class="column is-8">
          <div class="content">

            <p>
              This page was built using the <a href="https://github.com/eliahuhorwitz/Academic-project-page-template"
                target="_blank">Academic Project Page Template</a> which was adopted from the <a
                href="https://nerfies.github.io" target="_blank">Nerfies</a> project page.
              You are free to borrow from this website, we just ask that you link back to this page in the footer. <br>
              This website is licensed under a <a rel="license" href="http://creativecommons.org/licenses/by-sa/4.0/"
                target="_blank">Creative
                Commons Attribution-ShareAlike 4.0 International License</a>.
            </p>

          </div>
        </div>
      </div>
    </div>
  </footer>

  <script>
    bulmaCarousel.attach('#results-carousel', {
      autoplay: true,
      autoplaySpeed: 6000,
      loop: true
    });
  </script>
</body>

</html>
